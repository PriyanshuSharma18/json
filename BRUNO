import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime, timezone, timedelta
import time
import os
import re

# ===================== ENV LOADING =====================
def load_env(path: str = ".env") -> None:
    if not os.path.exists(path):
        return

    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            if '=' in line:
                key, value = line.split('=', 1)
                key = key.strip()
                value = value.strip().strip('"\'')
                if key not in os.environ:
                    os.environ[key] = value

# Load .env early
load_env()

IS_LOCAL_ENV = True # force true for now

# ===================== CONFIG =====================
ACCESS_TOKEN = os.environ.get("ACCESS_TOKEN")
USER_EMAIL = os.environ.get("USER_EMAIL")

if not ACCESS_TOKEN:
    raise RuntimeError("ACCESS_TOKEN is not set. Please set it in .env or code.")
if not USER_EMAIL:
    raise RuntimeError("USER_EMAIL is not set. Please set it in .env or code.")

headers = {
    "Authorization": f"Bearer {ACCESS_TOKEN}",
    "Prefer": 'outlook.body-content-type="html"'
}

OUTPUT_DIR = "email_extracts"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ===================== TIME HELPERS =====================

MONTH_MAP = {
    "jan":1, "feb":2, "mar":3, "apr":4, "may":5, "jun":6,
    "jul":7, "aug":8, "sep":9, "oct":10, "nov":11, "dec":12
}

def normalize_time_to_utc(raw: str, year: int) -> str | None:
    raw = raw.strip()

    # Format: HHMM/DD Mon
    m = re.match(r"(\d{3,4})/(\d{1,2})\s*([A-Za-z]{3})", raw)
    if m:
        hhmm, day, mon = m.groups()
        hour = int(hhmm[:-2])
        minute = int(hhmm[-2:])
        month = MONTH_MAP.get(mon.lower())
        if month:
            dt = datetime(year, month, int(day), hour, minute, tzinfo=timezone(timedelta(hours=5, minutes=30)))
            return dt.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

    # ISO-like format fallback
    if "T" in raw:
        try:
            dt = datetime.fromisoformat(raw.replace("Z", "+00:00"))
            return dt.astimezone(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
        except:
            return None

    # HH:MM only
    m = re.match(r"(\d{2}):(\d{2})", raw)
    if m:
        hour, minute = map(int, m.groups())
        # fallback assume same year/month/day as email year
        dt = datetime(year, datetime.now().month, datetime.now().day,
                      hour, minute, tzinfo=timezone.utc)
        return dt.strftime("%Y-%m-%dT%H:%M:%SZ")

    return None


def convert_utc_to_ist(utc_iso: str) -> str:
    try:
        dt = datetime.fromisoformat(utc_iso.replace("Z", "+00:00"))
        return dt.astimezone(timezone(timedelta(hours=5, minutes=30))).strftime("%Y-%m-%dT%H:%M:%SZ+05:30")
    except:
        return None


# ===================== UTILS =====================

def sanitize_filename(filename: str) -> str:
    return re.sub(r'[<>:"/\\|?*]', '_', filename)

def convert_to_ist_format(utc_datetime_str: str) -> str:
    try:
        dt = datetime.fromisoformat(utc_datetime_str.replace("Z", "+00:00"))
        return dt.astimezone(timezone(timedelta(hours=5, 30))).strftime("%Y-%m-%dT%H:%M:%SZ+05:30")
    except:
        return datetime.now(timezone(timedelta(hours=5, 30))).strftime("%Y-%m-%dT%H:%M:%SZ+05:30")

# ===================== FIELD LABEL CHECK =====================

def check_mandatory_fields_in_html(html_content: str):
    required_keys = {
        "station", "weatherPhenomenon", "operationProbability",
        "advisoryTimePeriodStartUTC", "advisoryTimePeriodEndUTC"
    }

    if not html_content:
        return list(required_keys)

    html_lower = html_content.lower()
    simple = re.sub(r'[^a-z0-9]', '', html_lower)
    present = set()

    if 'station' in html_lower: present.add("station")
    if ('weather' in html_lower and 'phenom' in html_lower): present.add("weatherPhenomenon")
    if ('operat' in html_lower and 'prob' in html_lower): present.add("operationProbability")
    if ('advisory' in html_lower and 'start' in html_lower): present.add("advisoryTimePeriodStartUTC")
    if ('advisory' in html_lower and 'end' in html_lower): present.add("advisoryTimePeriodEndUTC")

    missing = [k for k in required_keys if k not in present]
    return missing


# ===================== NLP-STYLE EXTRACTION =====================

def extract_weather_stations_nlp(html_content: str, email_year: int):
    soup = BeautifulSoup(html_content, "html.parser")
    text = soup.get_text("\n", strip=True)
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    stations = []
    i = 0

    while i < len(lines):
        if re.fullmatch(r"[A-Z]{3}", lines[i]):
            station_code = lines[i]
            entry = {"station": station_code}
            window = lines[i+1:i+15]

            # Probability
            for w in window:
                if re.fullmatch(r"\d{1,3}", w):
                    val = int(w)
                    if 0 <= val <= 100:
                        entry["operationProbability"] = val
                        break

            # Weather
            for w in window:
                if re.fullmatch(r"[A-Z]{2,6}", w) and w != station_code:
                    entry["weatherPhenomenon"] = w
                    break

            # Time extraction
            time_vals = []
            for w in window:
                norm = normalize_time_to_utc(w, email_year)
                if norm:
                    time_vals.append(norm)

            if len(time_vals) >= 2:
                entry["advisoryTimePeriodStartUTC"] = time_vals[0]
                entry["advisoryTimePeriodEndUTC"] = time_vals[1]
                entry["advisoryTimePeriodStartLT"] = convert_utc_to_ist(time_vals[0])
                entry["advisoryTimePeriodEndLT"] = convert_utc_to_ist(time_vals[1])

            if all(k in entry for k in [
                "station", "weatherPhenomenon", "operationProbability",
                "advisoryTimePeriodStartUTC", "advisoryTimePeriodEndUTC"
            ]):
                stations.append(entry)

        i += 1

    return stations


# ===================== GRAPH API =====================

def get_all_messages(page_size=50):
    url = (f"https://graph.microsoft.com/v1.0/users/{USER_EMAIL}/messages"
           f"?$top={page_size}&$orderby=receivedDateTime desc"
           "&$select=id,subject,receivedDateTime")
    final = []
    resp = requests.get(url, headers=headers)
    if resp.status_code == 200:
        final.extend(resp.json().get("value", []))
    return final

def get_message_body_html(msg_id):
    url = f"https://graph.microsoft.com/v1.0/users/{USER_EMAIL}/messages/{msg_id}?$select=body"
    r = requests.get(url, headers=headers)
    if r.status_code != 200:
        return ""
    return r.json().get("body", {}).get("content", "")


# ===================== MAIN PROCESSING =====================

def process_single_email(message):
    body_html = get_message_body_html(message["id"])
    if not body_html:
        return None

    missing = check_mandatory_fields_in_html(body_html)
    if missing:
        return None

    email_year = int(message["receivedDateTime"][:4])
    stations = extract_weather_stations_nlp(body_html, email_year)

    if not stations:
        return None

    return {
        "createdAt": convert_to_ist_format(message.get("receivedDateTime", "")),
        "stations": stations
    }


def process_all_emails():
    msgs = get_all_messages()
    extracted = skipped = 0

    for idx, msg in enumerate(msgs):
        print(f"\nüì© EMAIL {idx+1}: {msg.get('subject')}")
        result = process_single_email(msg)

        if result:
            fname = sanitize_filename(msg.get("subject", "No_Subject")[:30])
            filename = f"{idx+1:03d}_{fname}.json"
            with open(os.path.join(OUTPUT_DIR, filename), "w") as f:
                json.dump(result, f, indent=2)
            print(f"‚úî Saved {filename}")
            extracted += 1
        else:
            print("‚ö† Skipped")
            skipped += 1

    print("\n=== SUMMARY ===")
    print(f"‚úî Extracted: {extracted}")
    print(f"‚ö† Skipped: {skipped}")
    print("üìÅ Output:", OUTPUT_DIR)


if __name__ == "__main__":
    process_all_emails()
