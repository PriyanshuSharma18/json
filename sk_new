Awesome, thanks for pasting everything – that helps a LOT.

You’ve actually given me all the clues:

Reviewer service on 8802 is working (health = 200 ✅, /invoke gives 500 = internal error inside SK, we’ll handle later).

Writer service on 8002 is not the app we think it is (both /health and /invoke return 404 Not Found).

So:

http://localhost:8802/health → OK (reviewer)

http://localhost:8002/health → 404 (not our writer app)

That means the process listening on 8002 doesn’t have /health or /invoke routes – either:

Uvicorn is importing some other module called writer_service, or

Some other app is bound to 8002, not the file you pasted.

Instead of fighting import paths, I’ll give you a clean, minimal setup that:

Runs writer & reviewer as plain Python scripts (no uvicorn writer_service:app confusion).

Uses fixed ports 8801 (writer) and 8802 (reviewer).

Keeps your SK + Azure code as-is.

1️⃣ New folder (clean demo)

In C:\Users\Priyanshu.x.Sharma1\Downloads, make a new folder, e.g.:

PS> mkdir sk_agents_demo
PS> cd sk_agents_demo
PS> python -m venv venv
PS> .\venv\Scripts\activate
(venv) PS> pip install fastapi uvicorn semantic-kernel openai python-dotenv requests


Create a .env in sk_agents_demo:

AZURE_OPENAI_API_KEY=YOUR_REAL_KEY
AZURE_OPENAI_ENDPOINT=https://6e-openai-sandbox-aops.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o

2️⃣ writer_service.py (port 8801)
# writer_service.py
import os
from dataclasses import dataclass

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.functions import KernelFunctionFromPrompt


def build_kernel() -> Kernel:
    load_dotenv()

    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
    deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

    if not api_key or not endpoint or not deployment_name:
        raise RuntimeError(
            "Missing Azure env vars: AZURE_OPENAI_API_KEY / AZURE_OPENAI_ENDPOINT / AZURE_OPENAI_DEPLOYMENT_NAME"
        )

    print("[WriterService] Using endpoint:", endpoint)
    print("[WriterService] Using deployment:", deployment_name)

    kernel = Kernel()
    chat_service = AzureChatCompletion(
        service_id="azure-gpt4o",
        api_key=api_key,
        endpoint=endpoint,
        deployment_name=deployment_name,
        api_version=api_version,
    )
    kernel.add_service(chat_service)
    return kernel


@dataclass
class WriterAgent:
    kernel: Kernel

    def __post_init__(self):
        self._func = KernelFunctionFromPrompt(
            function_name="writer_agent",
            plugin_name="email_agents",
            prompt=(
                "You are an expert email writer agent.\n"
                "Task: Write a clear, concise, professional email.\n\n"
                "User intent / instructions:\n"
                "{{ $input }}\n\n"
                "Constraints:\n"
                "- Polite, professional tone.\n"
                "- Under 250 words.\n"
                "- Output ONLY the email body, no explanations."
            ),
        )

    async def run(self, instruction: str) -> str:
        result = await self.kernel.invoke(self._func, input=instruction)
        return str(result)


class AgentRequest(BaseModel):
    input: str


class AgentResponse(BaseModel):
    agent: str
    output: str


app = FastAPI(title="Writer Agent Service")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

print("[WriterService] Building kernel...")
kernel = build_kernel()
writer_agent = WriterAgent(kernel)
print("[WriterService] Ready.")


@app.post("/invoke", response_model=AgentResponse)
async def invoke_writer(payload: AgentRequest):
    print(f"[WriterService] Received request: {payload.input}")
    output = await writer_agent.run(payload.input)
    print(f"[WriterService] Generated output: {output}")
    return AgentResponse(agent="writer", output=output)


@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "writer"}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8801)


Note: we now start it with python writer_service.py, so we are definitely running this exact file.

3️⃣ reviewer_service.py (port 8802)
# reviewer_service.py
import os
from dataclasses import dataclass

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.functions import KernelFunctionFromPrompt


def build_kernel() -> Kernel:
    load_dotenv()

    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-12-01-preview")
    deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

    if not api_key or not endpoint or not deployment_name:
        raise RuntimeError(
            "Missing Azure env vars: AZURE_OPENAI_API_KEY / AZURE_OPENAI_ENDPOINT / AZURE_OPENAI_DEPLOYMENT_NAME"
        )

    print("[ReviewerService] Using endpoint:", endpoint)
    print("[ReviewerService] Using deployment:", deployment_name)

    kernel = Kernel()
    chat_service = AzureChatCompletion(
        service_id="azure-gpt4o",
        api_key=api_key,
        endpoint=endpoint,
        deployment_name=deployment_name,
        api_version=api_version,
    )
    kernel.add_service(chat_service)
    return kernel


@dataclass
class ReviewerAgent:
    kernel: Kernel

    def __post_init__(self):
        self._func = KernelFunctionFromPrompt(
            function_name="reviewer_agent",
            plugin_name="email_agents",
            prompt=(
                "You are an email reviewer and improver agent.\n"
                "You will receive a draft email between triple backticks.\n\n"
                "Draft email:\n"
                "```{{ $input }}```\n\n"
                "Your job:\n"
                "- Fix grammar, tone, and clarity.\n"
                "- Keep the original intent.\n"
                "- Improve professionalism but stay human.\n"
                "- Output ONLY the improved email body, no explanations."
            ),
        )

    async def run(self, draft_email: str) -> str:
        result = await self.kernel.invoke(self._func, input=draft_email)
        return str(result)


class AgentRequest(BaseModel):
    input: str


class AgentResponse(BaseModel):
    agent: str
    output: str


app = FastAPI(title="Reviewer Agent Service")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

print("[ReviewerService] Building kernel...")
kernel = build_kernel()
reviewer_agent = ReviewerAgent(kernel)
print("[ReviewerService] Ready.")


@app.post("/invoke", response_model=AgentResponse)
async def invoke_reviewer(payload: AgentRequest):
    print(f"[ReviewerService] Received request: {payload.input}")
    output = await reviewer_agent.run(payload.input)
    print(f"[ReviewerService] Generated output: {output}")
    return AgentResponse(agent="reviewer", output=output)


@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "reviewer"}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8802)

4️⃣ host_orchestrator.py (A2A router)
# host_orchestrator.py
import sys
import requests

WRITER_URL = "http://localhost:8801/invoke"
REVIEWER_URL = "http://localhost:8802/invoke"


def call_agent(url: str, text: str) -> str:
    try:
        resp = requests.post(url, json={"input": text}, timeout=120)
        print(f"[Host] {url} -> status {resp.status_code}")
        if resp.status_code != 200:
            print(f"[Host] Response content: {resp.text}")
        resp.raise_for_status()
        data = resp.json()
        return data["output"]
    except requests.exceptions.RequestException as e:
        print(f"[Error] Failed to call {url}: {e}")
        raise


def main():
    if len(sys.argv) > 1:
        instruction = " ".join(sys.argv[1:])
    else:
        print("Enter instructions for the email:")
        instruction = input("> ").strip()

    if not instruction:
        print("No instruction provided. Exiting.")
        return

    print("\n[Host] Calling Writer Agent at", WRITER_URL)
    draft = call_agent(WRITER_URL, instruction)
    print("\n[Host] Writer Agent draft:\n")
    print(draft)

    print("\n[Host] Calling Reviewer Agent at", REVIEWER_URL)
    final_email = call_agent(REVIEWER_URL, draft)
    print("\n[Host] Reviewer Agent final email:\n")
    print(final_email)

    print("\n================ FINAL EMAIL (READY TO SEND) ================\n")
    print(final_email)
    print("\n=============================================================\n")


if __name__ == "__main__":
    main()

5️⃣ How to run (3 terminals)

In sk_agents_demo, with venv active:

Terminal 1 – writer

(venv) PS> python writer_service.py
# watch logs


Visit http://localhost:8801/health → should return JSON, and terminal shows GET.

Terminal 2 – reviewer

(venv) PS> python reviewer_service.py


Visit http://localhost:8802/health → JSON + logs.

Terminal 3 – host

(venv) PS> python host_orchestrator.py "Write an email to my manager about today's Semantic Kernel + A2A POC progress"


You should see:

Host logs

Draft from writer

Final from reviewer
